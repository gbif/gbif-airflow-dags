apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
{% if timestamp is defined and computed_name is not defined %}
metadata:
  name: {{ sparkName.lower() }}-{{ timestamp.lower() }}
{% elif computed_name is defined %}
metadata:
  name: {{ computed_name.lower() }}
{% else %}
metadata:
  name: {{ sparkName }}
{% endif %}
spec:
  version: {{ version }}
  image: docker.gbif.org/{{ component }}:{{ version }}
  sparkImage: docker.stackable.tech/stackable/spark-k8s:3.3.0-stackable23.7.0
  mode: cluster
  mainApplicationFile: local:///stackable/spark/jobs/{{ component }}.jar
  mainClass: {{ main }}
  args:
{%- for arg in args %}
    - "{{arg}}"
{%- endfor %}
  deps:
    repositories:
      - https://repository.gbif.org/repository/central/
    packages:
      - org.apache.spark:spark-avro_2.12:3.3.0
  sparkConf:
{%- raw %}
     "spark.driver.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
     "spark.executor.extraJavaOptions": "-XX:+UseConcMarkSweepGC"
     "spark.jars.ivy": "/tmp"
     "spark.broadcast.compress": "true"
     "spark.checkpoint.compress": "true"
     "spark.executor.memoryOverhead": "4096"
     "spark.executor.heartbeatInterval": "10s"
     "spark.network.timeout": "60s"
     "spark.io.compression.codec": "lz4"
     "spark.rdd.compress": "true"
     "spark.driver.extraClassPath": "/etc/hadoop/conf/:/etc/gbif/:/stackable/spark/extra-jars/*"
     "spark.executor.extraClassPath": "/etc/hadoop/conf/:/etc/gbif/:/stackable/spark/extra-jars/*"
     "spark.kubernetes.authenticate.driver.serviceAccountName": "gbif-spark-sa"
     "spark.kubernetes.scheduler.name": "yunikorn"
     "spark.kubernetes.driver.label.queue": "root.default"
     "spark.kubernetes.executor.label.queue": "root.default"
     "spark.kubernetes.driver.annotation.yunikorn.apache.org/app-id": "{{APP_ID}}"
     "spark.kubernetes.executor.annotation.yunikorn.apache.org/app-id": "{{APP_ID}}"
{%- endraw %}
{% if componentConfig is defined or hdfsClusterName is defined or hiveClusterName is defined or hbaseClusterName is defined %}
  volumes:
{% if componentConfig is defined %}
    - name: gbif-config
      configMap:
        name: {{ componentConfig }}-conf
{% endif %}
{% if componentProperty is defined %}
    - name: gbif-property
      configMap:
        name: {{ componentProperty.propertyName }}-conf
{% endif %}
{% if hdfsClusterName is defined %}
    - name: hdfs-env
      configMap:
        name: {{ hdfsClusterName }}
        items:
        - key: core-site.xml
          path: core-site.xml
        - key: hdfs-site.xml
          path: hdfs-site.xml
{% endif %}
{% if hiveClusterName is defined %}
    - name: hive-env
      configMap:
        name: {{ hiveClusterName }}-custom
        items:
        - key: hive-site.xml
          path: hive-site.xml
{% endif %}
{% if hbaseClusterName is defined %}
    - name: hbase-env
      configMap:
        name: {{ hbaseClusterName }}
        items:
        - key: hbase-site.xml
          path: hbase-site.xml
{% endif %}
{% endif %}
  driver:
    podOverrides:
      metadata:
        annotations:
          yunikorn.apache.org/task-group-name: "spark-driver"
          yunikorn.apache.org/task-groups: >- 
            [{
                name: "spark-driver",
                minMember: 1,
                minResource: {
                  cpu: 1,
                  memory: 2Gi
                }
              },
              {
                name: "spark-executor",
                minMember: 3,
                minResource: {
                  cpu: 1,
                  memory: 2Gi
                }
            }]
    resources:
      cpu:
        min: "100m"
        max: "{{ driverCores }}"
      memory:
        limit: "{{ driverMemory }}"
    volumeMounts:
{% if componentConfig is defined %}
      - name: gbif-config
        mountPath: /etc/gbif/config.yaml
        subPath: config.yaml
{% endif %}
{% if componentProperty is defined %}
      - name: gbif-property
        mountPath: {{ componentProperty.path }}{{ componentProperty.file }}
        subPath: {{ componentProperty.file }}
{% endif %}
{% if hdfsClusterName is defined %}
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/core-site.xml
        subPath: core-site.xml
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/hdfs-site.xml
        subPath: hdfs-site.xml
{% endif %}
{% if hiveClusterName is defined %}
      - name: hive-env
        mountPath: /etc/hadoop/conf/hive-site.xml
        subPath: hive-site.xml
{% endif %}
{% if hbaseClusterName is defined %}
      - name: hbase-env
        mountPath: /etc/hadoop/conf/hbase-site.xml
        subPath: hbase-site.xml
{% endif %}
  executor:
    podOverrides:
      metadata:
        annotations:
          yunikorn.apache.org/task-group-name: "spark-executor"
    instances: {{ executorInstances }}
    resources:
      cpu:
        min: "100m"
        max: "{{ executorCores }}"
      memory:
        limit: "{{ executorMemory }}"
    volumeMounts:
{% if componentConfig is defined %}
      - name: gbif-config
        mountPath: /etc/gbif/config.yaml
        subPath: config.yaml
{% endif %}
{% if componentProperty is defined %}
      - name: gbif-property
        mountPath: {{ componentProperty.path }}{{ componentProperty.file }}
        subPath: {{ componentProperty.file }}
{% endif %}
{% if hdfsClusterName is defined %}
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/core-site.xml
        subPath: core-site.xml
      - name: hdfs-env
        mountPath: /etc/hadoop/conf/hdfs-site.xml
        subPath: hdfs-site.xml
{% endif %}
{% if hiveClusterName is defined %}
      - name: hive-env
        mountPath: /etc/hadoop/conf/hive-site.xml
        subPath: hive-site.xml
{% endif %}
{% if hbaseClusterName is defined %}
      - name: hbase-env
        mountPath: /etc/hadoop/conf/hbase-site.xml
        subPath: hbase-site.xml
{% endif %}